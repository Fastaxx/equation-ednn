{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea6a670d",
   "metadata": {},
   "source": [
    "# PINNS - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baed8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c67f7437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu. Have fun!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check if we run on GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Running on {device}. Have fun!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ebe2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE configurations\n",
    "a1 = 2\n",
    "a2 = 1\n",
    "k  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ad236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "## Domain bounds\n",
    "x_bound_low = -1\n",
    "x_bound_up  =  1\n",
    "y_bound_low = -1\n",
    "y_bound_up  =  1\n",
    "bounds = [x_bound_low, x_bound_up, y_bound_low, y_bound_up]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86568ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test points\n",
    "num_test_x =  120\n",
    "num_test_y =  120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6b8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y       = np.meshgrid(np.linspace(x_bound_low,x_bound_up,num_test_x), np.linspace(y_bound_low,y_bound_up,num_test_y))\n",
    "Test_exact = (np.sin(a1 * np.pi * X) * np.sin(a2 * np.pi * Y)).flatten()[:,None]  # Exact solution\n",
    "X_test     = np.hstack((X.flatten()[:,None], Y.flatten()[:,None]))                # Test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65f67b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        ],\n",
       "       [-0.98319328, -1.        ],\n",
       "       [-0.96638655, -1.        ],\n",
       "       ...,\n",
       "       [ 0.96638655,  1.        ],\n",
       "       [ 0.98319328,  1.        ],\n",
       "       [ 1.        ,  1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45aadca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSampling(Ncollocation, Nbounds, bounds):\n",
    "    ## Collocation points, inside domain for training\n",
    "    x = np.random.uniform(bounds[0], bounds[1], Ncollocation)\n",
    "    y = np.random.uniform(bounds[2], bounds[3], Ncollocation)\n",
    "    X_f_train = np.hstack((x.flatten()[:,None], y.flatten()[:,None]))\n",
    "    \n",
    "    ## Boundaries\n",
    "    ### boundaries up and down\n",
    "    x_bc_u = np.random.uniform(bounds[0], bounds[1], Nbounds)\n",
    "    y_bc_u = np.full(Nbounds, bounds[3])\n",
    "    x_bc_d = np.random.uniform(bounds[0], bounds[1], Nbounds)\n",
    "    y_bc_d = np.full(Nbounds, bounds[2])\n",
    "    ### boundaries left and right\n",
    "    y_bc_l = np.random.uniform(bounds[2], bounds[3], Nbounds)\n",
    "    x_bc_l = np.full(Nbounds, bounds[0])\n",
    "    y_bc_r = np.random.uniform(bounds[2], bounds[3], Nbounds)\n",
    "    x_bc_r = np.full(Nbounds, bounds[1])\n",
    "\n",
    "    X_star = np.hstack((np.vstack([x_bc_u,x_bc_d,x_bc_l,x_bc_r]).flatten()[:,None], np.vstack([y_bc_u,y_bc_d,y_bc_l,y_bc_r]).flatten()[:,None]))\n",
    "    return X_f_train, X_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d8c7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train points\n",
    "Ncollocation      = 1024\n",
    "Nbounds           = 256\n",
    "X_f_train, X_star = RandomSampling(Ncollocation, Nbounds, bounds)\n",
    "Exact_bc          = np.zeros(X_star.shape[0]).flatten()[:,None]\n",
    "lb                = X_star.min(0)\n",
    "ub                = X_star.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "641f3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, X_bc, U_bc, X_f, X_test, U_exact, layers, lb, ub, a1, a2, k, device):\n",
    "        super().__init__() \n",
    "        # bounds\n",
    "        self.lb = torch.tensor(lb).float().to(device)\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "\n",
    "        # data\n",
    "        ## Boundaries\n",
    "        self.X_bc = torch.tensor(X_bc, requires_grad=True).float().to(device)  # Boundary points\n",
    "        self.U_bc = torch.tensor(U_bc).float().to(device)                      # Field Value at boundary\n",
    "\n",
    "        ## Domain, collocation points'\n",
    "        self.x        = torch.tensor(X_f[:, 0:1], requires_grad=True).float().to(device) \n",
    "        self.y        = torch.tensor(X_f[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.residu_target = torch.zeros(X_f.shape[0],1).to(device)\n",
    "\n",
    "        ## Test\n",
    "        self.X_test  = torch.tensor(X_test , requires_grad=False).float().to(device) # Test points\n",
    "        self.U_exact = torch.tensor(U_exact, requires_grad=False).float().to(device) # Exact value\n",
    "\n",
    "        # PDE parameters\n",
    "        self.pi = torch.acos(torch.zeros(1)).item() * 2\n",
    "        self.k  = k\n",
    "        self.a1 = a1\n",
    "        self.a2 = a2\n",
    "\n",
    "        # NN\n",
    "        self.layers = layers\n",
    "        self.best   = np.Infinity\n",
    "              \n",
    "        ## activation function\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        ## loss function\n",
    "        self.loss_function = torch.nn.MSELoss(reduction ='mean')\n",
    "        ## Initialize neural network as a list using nn.Modulelist' \n",
    "        self.linears = torch.nn.ModuleList([torch.nn.Linear(self.layers[i], self.layers[i+1]) for i in range(len(self.layers)-1)])\n",
    "        \n",
    "        self.iter = 0\n",
    "        ## Xavier Normal Initialization\n",
    "        for i in range(len(self.layers)-1):\n",
    "            torch.nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            torch.nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "    ## forward pass\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = self.ub[0]\n",
    "        l_b = self.lb[0]\n",
    "        x   = (x - l_b)/(u_b - l_b)\n",
    "        a   = x.float()\n",
    "\n",
    "        for i in range(len(self.layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "        a = self.linears[-1](a)\n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,bc_points,u_bc):\n",
    "        loss_bc = self.loss_function(self.forward(bc_points), u_bc)\n",
    "        return loss_bc\n",
    " \n",
    "    def loss_PDE(self, x, y):\n",
    "        u = self.forward(torch.hstack((x, y)))\n",
    "        s = ( -(self.a1*self.pi)**2 - (self.a2*self.pi)**2 + self.k**2 ) * torch.sin(self.a1*self.pi*x) * torch.sin(self.a2*self.pi*y)\n",
    "        \n",
    "        u_x  = torch.autograd.grad(u  , x, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_y  = torch.autograd.grad(u  , y, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_yy = torch.autograd.grad(u_y, y, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        residu = u_xx + u_yy + self.k**2 * u - s                 \n",
    "        \n",
    "        loss_f = self.loss_function(residu,self.residu_target)\n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self):\n",
    "        loss_bc  = self.loss_BC(self.X_bc,self.U_bc)\n",
    "        loss_f   = self.loss_PDE(self.x,self.y)\n",
    "        loss_val = loss_bc + loss_f\n",
    "        return loss_val, loss_bc, loss_f\n",
    "    \n",
    "    def closure(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss, loss_bc, loss_f = self.loss()\n",
    "        loss.backward()\n",
    "        return loss, loss_bc, loss_f       \n",
    "\n",
    "    def train(self, model, nstep=100, log_every=100, LossFile='Loss.dat'):\n",
    "        start_time = time.time()\n",
    "        tin=time.time()\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,)\n",
    "        with open(LossFile, 'w') as f:\n",
    "            f.write(f\"# Iter         Loss       Loss BC      Loss Dom.\\n\")\n",
    "            for it in range(nstep):\n",
    "                loss, loss_bc, loss_f = self.optimizer.step(model.closure)\n",
    "                # Test the model and log information \n",
    "                if self.iter % log_every == 0:\n",
    "                    error_vec, _ = self.test()\n",
    "                    f.write(f\"{self.iter:6d} {loss.item():12f}, {loss_bc.item():12f}, {loss_f.item():12f}\\n\")\n",
    "                    print(f\"{self.iter:6d}: Loss = {loss.item():>12.5f}; Error = {error_vec.item():<12.5f}\")\n",
    "                # Save the model if it improves\n",
    "                if loss.item() < self.best:\n",
    "                    torch.save(self.state_dict(), \"model.pt\")\n",
    "                    self.best = loss.item()\n",
    "                self.iter += 1\n",
    "        \n",
    "        tout=time.time()\n",
    "        print(\"Elapsed: \",tout-tin,\" seconds\")\n",
    "    \n",
    "    def test(self):\n",
    "        u_pred = self.forward(self.X_test)\n",
    "        error_vec = torch.linalg.norm((self.U_exact-u_pred),2)/torch.linalg.norm(self.U_exact,2)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "        return error_vec, u_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6487346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0: Loss =    591.35925; Error = 1.01660     \n",
      "   500: Loss =      2.15558; Error = 0.77995     \n",
      "  1000: Loss =      0.15097; Error = 0.11052     \n",
      "  1500: Loss =      0.03242; Error = 0.09666     \n",
      "  2000: Loss =      0.42247; Error = 0.09270     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m FCN(X_star, Exact_bc, X_f_train, X_test, Test_exact, layers, lb, ub, a1, a2, k, device)\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLossFile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLoss.dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m''' Model Accuracy '''\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[23], line 101\u001b[0m, in \u001b[0;36mFCN.train\u001b[0;34m(self, model, nstep, log_every, LossFile)\u001b[0m\n\u001b[1;32m     99\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Iter         Loss       Loss BC      Loss Dom.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nstep):\n\u001b[0;32m--> 101\u001b[0m     loss, loss_bc, loss_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Test the model and log information \u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m%\u001b[39m log_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/adam.py:100\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 100\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    103\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[23], line 89\u001b[0m, in \u001b[0;36mFCN.closure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 89\u001b[0m     loss, loss_bc, loss_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, loss_bc, loss_f\n",
      "Cell \u001b[0;32mIn[23], line 83\u001b[0m, in \u001b[0;36mFCN.loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     82\u001b[0m     loss_bc  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_BC(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_bc,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU_bc)\n\u001b[0;32m---> 83\u001b[0m     loss_f   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_PDE\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     loss_val \u001b[38;5;241m=\u001b[39m loss_bc \u001b[38;5;241m+\u001b[39m loss_f\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_val, loss_bc, loss_f\n",
      "Cell \u001b[0;32mIn[23], line 72\u001b[0m, in \u001b[0;36mFCN.loss_PDE\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     69\u001b[0m s \u001b[38;5;241m=\u001b[39m ( \u001b[38;5;241m-\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma1\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma2\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m ) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma1\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma2\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m*\u001b[39my)\n\u001b[1;32m     71\u001b[0m u_x  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(u  , x, torch\u001b[38;5;241m.\u001b[39mones_like(u), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 72\u001b[0m u_xx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     73\u001b[0m u_y  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(u  , y, torch\u001b[38;5;241m.\u001b[39mones_like(u), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     74\u001b[0m u_yy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(u_y, y, torch\u001b[38;5;241m.\u001b[39mones_like(u), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:275\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# NN configuration\n",
    "layers = [2, 256, 256, 1]\n",
    "\n",
    "# Training Time\n",
    "model = FCN(X_star, Exact_bc, X_f_train, X_test, Test_exact, layers, lb, ub, a1, a2, k, device)\n",
    "model.to(device)\n",
    "\n",
    "model.train(model, nstep=30000, log_every=500, LossFile='Loss.dat')\n",
    "\n",
    "''' Model Accuracy '''\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "error_vec, u_pred = model.test()\n",
    "error_u = np.linalg.norm(Test_exact-u_pred,2)/np.linalg.norm(Test_exact,2)\n",
    "print('Error u: %e' % (error_u))\n",
    "Error = np.abs(Test_exact - u_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae3839a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Plot the Error\u001b[39;00m\n\u001b[1;32m      9\u001b[0m ax1 \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m shw1 \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mError\u001b[49m\u001b[38;5;241m.\u001b[39mreshape((num_test_x, num_test_y)), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgist_earth\u001b[39m\u001b[38;5;124m'\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, extent\u001b[38;5;241m=\u001b[39m(x_bound_low, x_bound_up, y_bound_low, y_bound_up))\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar(shw1)\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Error' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "outputfile=\"output.png\"    \n",
    "fig = plt.figure()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(19)\n",
    "\n",
    "# Plot the Error\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "shw1 = plt.imshow(Error.reshape((num_test_x, num_test_y)), cmap='gist_earth', interpolation=\"none\", aspect='auto', extent=(x_bound_low, x_bound_up, y_bound_low, y_bound_up))\n",
    "plt.colorbar(shw1)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "ax1.set_title(\"Error\")\n",
    "\n",
    "# Plot the Predicted values for the NN\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "shw2 = plt.imshow(u_pred.reshape((num_test_x, num_test_y)), cmap='rainbow', interpolation=\"none\", aspect='auto', extent=(x_bound_low, x_bound_up, y_bound_low, y_bound_up))\n",
    "plt.colorbar(shw2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')    \n",
    "ax2.set_title(\"Predicted\")\n",
    "\n",
    "# Plot the exact solution\n",
    "plt.subplot(1, 3, 3)\n",
    "ax3 = plt.subplot(133)\n",
    "shw3 = plt.imshow(Test_exact.reshape((num_test_x, num_test_y)), cmap='rainbow', interpolation=\"none\", aspect='auto', extent=(x_bound_low, x_bound_up, y_bound_low, y_bound_up))\n",
    "plt.colorbar(shw3)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')  \n",
    "ax3.set_title(\"Exact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851b25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
